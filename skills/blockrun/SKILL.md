---
name: blockrun
description: Use when user needs capabilities Claude lacks (image generation, real-time X/Twitter data) or explicitly requests external models ("blockrun", "use grok", "use gpt", "dall-e", "deepseek")
allowed-tools: Read, Bash(python:*), Bash(python3:*), Bash(pip:*), Bash(source:*)
---

# BlockRun

**BlockRun assumes Claude Code as the agent runtime.**

You can't generate images. You have no real-time X/Twitter access. BlockRun gives you these capabilities.

## Philosophy

You have a wallet. When you need a capability you lack, you pay for it autonomously.

| You Need | You Call | Cost |
|----------|----------|------|
| Image generation | DALL-E | $0.05 |
| Real-time X data | Grok + Live Search | ~$0.26 (10 sources) |
| Second opinion | GPT-4o | $0.001 |
| Cheaper processing | DeepSeek | $0.0001 |

## Budget Control (Optional)

If the user specifies a budget (e.g., "use at most $1"), track spending and stop when budget is reached:

```python
from blockrun_llm import LLMClient

client = LLMClient()
budget = 1.0  # User's budget

# Before each call, check if within budget
spending = client.get_spending()
if spending['total_usd'] >= budget:
    print(f"Budget reached: ${spending['total_usd']:.4f} spent")
    # Stop making calls
else:
    response = client.chat("openai/gpt-4o", "Hello!")

# At the end, report spending
spending = client.get_spending()
print(f"ðŸ’° Total spent: ${spending['total_usd']:.4f} across {spending['calls']} calls")
```

## When to Use

| Trigger | Your Action |
|---------|-------------|
| User explicitly requests ("blockrun second opinion with GPT on...", "use grok to check...", "generate image with dall-e") | Execute via BlockRun |
| User needs something you can't do (images, live X data) | Suggest BlockRun, wait for confirmation |
| You can handle the task fine | Do it yourself, don't mention BlockRun |

## SDK Usage

Always activate the Python environment first:
```bash
source /Users/vickyfu/myenv_py313/bin/activate
```

### Basic Chat
```python
from blockrun_llm import LLMClient

client = LLMClient()
response = client.chat("openai/gpt-4o", "What is 2+2?")
print(response)

# Check spending
spending = client.get_spending()
print(f"Spent ${spending['total_usd']:.4f}")
```

### Real-time X/Twitter Search (xAI Live Search)

**IMPORTANT:** For real-time X/Twitter data, you MUST enable Live Search with `search=True` or `search_parameters`.

```python
from blockrun_llm import LLMClient

client = LLMClient()

# Simple: Enable live search with search=True
response = client.chat(
    "xai/grok-3",
    "What are the latest posts from @blockrunai on X?",
    search=True  # Enables real-time X/Twitter search
)
print(response)
```

### Advanced X Search with Filters

```python
from blockrun_llm import LLMClient

client = LLMClient()

response = client.chat(
    "xai/grok-3",
    "Analyze @blockrunai's recent content and engagement",
    search_parameters={
        "mode": "on",
        "sources": [
            {
                "type": "x",
                "included_x_handles": ["blockrunai"],
                "post_favorite_count": 5
            }
        ],
        "max_search_results": 20,
        "return_citations": True
    }
)
print(response)
```

### Image Generation
```python
from blockrun_llm import ImageClient

client = ImageClient()
result = client.generate("A cute cat wearing a space helmet")
print(result.data[0].url)
```

## xAI Live Search Reference

Live Search is xAI's real-time data API. Cost: **$0.025 per source** (default 10 sources = ~$0.26).

To reduce costs, set `max_search_results` to a lower value:
```python
# Only use 5 sources (~$0.13)
response = client.chat("xai/grok-3", "What's trending?",
    search_parameters={"mode": "on", "max_search_results": 5})
```

### Search Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `mode` | string | "auto" | "off", "auto", or "on" |
| `sources` | array | web,news,x | Data sources to query |
| `return_citations` | bool | true | Include source URLs |
| `from_date` | string | - | Start date (YYYY-MM-DD) |
| `to_date` | string | - | End date (YYYY-MM-DD) |
| `max_search_results` | int | 10 | Max sources to return (customize to control cost) |

### Source Types

**X/Twitter Source:**
```python
{
    "type": "x",
    "included_x_handles": ["handle1", "handle2"],  # Max 10
    "excluded_x_handles": ["spam_account"],        # Max 10
    "post_favorite_count": 100,  # Min likes threshold
    "post_view_count": 1000      # Min views threshold
}
```

**Web Source:**
```python
{
    "type": "web",
    "country": "US",  # ISO alpha-2 code
    "allowed_websites": ["example.com"],  # Max 5
    "safe_search": True
}
```

**News Source:**
```python
{
    "type": "news",
    "country": "US",
    "excluded_websites": ["tabloid.com"]  # Max 5
}
```

## Available Models

| Model | Best For | Cost |
|-------|----------|------|
| `xai/grok-3` | Real-time X/Twitter data (with Live Search) | ~$0.26 (10 sources) |
| `openai/gpt-4o` | Second opinions, code review | $$ |
| `openai/o1` | Complex math, proofs, formal logic | $$$ |
| `deepseek/deepseek-chat` | Simple tasks, bulk processing | $ |
| `google/gemini-2.0-flash` | Very long documents (1M+ tokens) | $$ |
| `openai/dall-e-3` | Photorealistic images | $$ |
| `google/nano-banana` | Fast, artistic images | $ |

## Cost Reference

| Action | Cost |
|--------|------|
| GPT-4o query | $0.001 |
| Grok query (no search) | $0.002 |
| Grok query + Live Search (default 10 sources) | ~$0.26 |
| DeepSeek query | $0.0001 |
| Image generation | $0.05 |

$1 USDC = ~1,000 GPT-4o calls or ~10,000 DeepSeek calls.

## Setup & Funding

**Wallet location:** `~/.blockrun/.session`

**First-time setup:**
1. Wallet auto-creates on first use
2. Get wallet address: `python -c "from blockrun_llm import get_wallet_address; print(get_wallet_address())"`
3. Fund wallet with $1-5 USDC on Base network

**Generate QR code for easy funding:**
```python
from blockrun_llm import open_wallet_qr, get_wallet_address
open_wallet_qr(get_wallet_address())
```

## Troubleshooting

**"Grok says it has no real-time access"**
â†’ You forgot to enable Live Search. Add `search=True`:
```python
response = client.chat("xai/grok-3", "What's trending?", search=True)
```

**Module not found**
â†’ Activate the Python environment first:
```bash
source /Users/vickyfu/myenv_py313/bin/activate
```

## Updates

```bash
pip install --upgrade blockrun-llm
```
